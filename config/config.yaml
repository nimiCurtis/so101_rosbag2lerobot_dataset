# =============================
# Global
# =============================
out_dir: "./local_dataset_ros2"          # local output directory
data_dir_name: "lerobot_dataset_example" # name of dataset inside HF repo
repo_id: "your-hf-username/your-dataset" # set your HF repo here
episode_per_bag: true                    # split each rosbag into one episode
downsample_by: 1                         # use every frame

# pick one of: image:<name> | state | action
# when using images, set to "image:wrist" (or any listed below)
sync_reference: "image:wrist"      
sync_tolerance_s: 0.010                  # max time diff for sync (in seconds). Should be <= 1/fps.

use_videos: true
fps: 30
video:
  codec: "av1"
  pix_fmt: "yuv420p"
  is_depth_map: false
  has_audio: false
  backend: "pyav"
  writer_processes: 4
  writer_threads: 4

# ---- Observation & Action schema ----
# Both are 6-D joint vectors (float32), e.g., joint angles in radians or normalized units.
state:
  key: "observation.state"
  size: 6
action:
  key: "action"
  size: 6

# Use Lerobot normalized ranges for joints
use_lerobot_ranges_norms: false

# If you want a specific joint order, list exactly 6 names (must match JointState.name).
# If left empty, the converter takes the FIRST 6 positions in the message.
joint_order: ["shoulder_pan", "shoulder_lift", "elbow_flex", "wrist_flex", "wrist_roll", "gripper"]

# multiple image streams; each has its own key, shape, and topic
images:
  wrist:
    key: "observation.images.wrist"
    shape: [360, 640, 3]
    topic: "/follower/cam_front/image_raw"

# ROS 2 topics (ALL REQUIRED; set action to same as state if needed)
topics:
  state:  "/follower/joint_states"               # sensor_msgs/JointState
  action: "/leader/joint_commands"  # std_msgs/Float64MultiArray

bags_root: "/home/nimrod/dev/so101_rosbag2lerobot_dataset/bag"
task_text: "pick and place"
